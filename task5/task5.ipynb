{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据分析/处理\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 搭建神经网络\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "# 数据可视化\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# word2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d83a665410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证cuda是否可用\n",
    "cuda_available=torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
    "if cuda_available:\n",
    "    print(\"CUDA Device Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Compute Capability:\", torch.cuda.get_device_capability(0))\n",
    "# 宇宙的答案\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读入数据\n",
    "\n",
    "由于是中文诗词，且需要进行字符级建模，所以需要搭建字典并切分句子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "# 首先将整个语料库读入，并对其进行清洗和重新划分。\n",
    "poe=open(\"poetryFromTang.txt\",'r')\n",
    "poem=poe.read()\n",
    "poe.close()\n",
    "# 将诗词按句号划分\n",
    "tmp=poem.replace(poem[0],\"\")\n",
    "tmp=tmp.replace(\" \",\"\")\n",
    "tmp=tmp.replace(\"。\",\"。\\n\")\n",
    "# 检查有无乱码\n",
    "if('a' in tmp):\n",
    "    print(\"yes\")\n",
    "# 诗词中有乱码，推测为拼音需要在分词时注意\n",
    "# 作为新文件保存\n",
    "newFile=open(\"NewPoetryFromTang.txt\",'w')\n",
    "newFile.write(tmp)\n",
    "newFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['君', '问', '归', '期', '未', '有', '期', '，', '巴', '山', '夜', '雨', '空', '秋', '池', '。']\n"
     ]
    }
   ],
   "source": [
    "corprus=pd.read_csv(\"NewPoetryFromTang.txt\",header=None,delimiter='\\t')\n",
    "max_len=corprus[0].str.len().max()\n",
    "# print(max_len)\n",
    "def sen2list(sentence):\n",
    "    pattern=r'[a-zA-Z0-9]+'\n",
    "    match=re.findall(pattern,sentence)\n",
    "    # 把句子中的拼音全换成中文字符“空”\n",
    "    for m in match:\n",
    "        sentence=sentence.replace(m,\"空\")\n",
    "    l=[w for w in sentence]\n",
    "    return l\n",
    "s=sen2list(\"君问归期未有期，巴山夜雨zhangqiu1秋池。\")\n",
    "print(s)\n",
    "\n",
    "corprus=corprus[0].apply(sen2list).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用word2vec得到对应的word2vec\n",
    "# 将向量维度设置为50，同时由于是字符级别的模型，所以对所有的字符都要训练，min_count需要设置为1\n",
    "wvmodel=Word2Vec(corprus,vector_size=50,sg=1,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02159202, -0.03349001, -0.04736485,  0.09071317, -0.01452516,\n",
       "       -0.13695037,  0.07575325,  0.14807402, -0.10778531, -0.01217772,\n",
       "       -0.03407127, -0.04166519, -0.02607638,  0.12653652, -0.12478288,\n",
       "        0.02732991, -0.01574592,  0.05789427, -0.2224392 , -0.08616893,\n",
       "        0.053178  ,  0.07778005,  0.18014918, -0.10958737,  0.10932513,\n",
       "       -0.02118833, -0.01260017, -0.05897688, -0.16173272,  0.02780469,\n",
       "        0.07224127, -0.04969627, -0.01044901,  0.06253659, -0.15252413,\n",
       "        0.08228706,  0.12177187, -0.05846209,  0.05054614, -0.08211034,\n",
       "        0.14143018, -0.01661082, -0.03055685,  0.0646854 ,  0.23934047,\n",
       "       -0.02147242, -0.00454188, -0.05778379,  0.09433985,  0.10131933],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例子\n",
    "wvmodel.wv[\"巴\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n"
     ]
    }
   ],
   "source": [
    "def sen2word2vec(sentence_list,model,maxlen=max_len):\n",
    "    vecList=np.zeros((maxlen,model.vector_size)) \n",
    "    # vecList=np.zeros((len(sentence_list),model.vector_size)) \n",
    "    \n",
    "    if(sentence_list==[]):\n",
    "        return vecList \n",
    "    # 将列表句子转化为稠密词向量句子\n",
    "    # vecList=np.array([])\n",
    "    for i,e in enumerate(sentence_list):\n",
    "        if(e in model.wv):\n",
    "            vecList[i]=model.wv[e]\n",
    "    return vecList\n",
    "\n",
    "s=['巴','山','夜']\n",
    "p=sen2word2vec(s,wvmodel)\n",
    "print(len(p))\n",
    "print(p[0]==wvmodel.wv['巴'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14550\n",
      "[['巴', '山'], ['巴', '山', '上'], ['巴', '山', '上', '峡'], ['巴', '山', '上', '峡', '重'], ['巴', '山', '上', '峡', '重', '复'], ['巴', '山', '上', '峡', '重', '复', '重'], ['巴', '山', '上', '峡', '重', '复', '重', '，'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台', '碧'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台', '碧', '峭'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台', '碧', '峭', '十'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台', '碧', '峭', '十', '二'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台', '碧', '峭', '十', '二', '峰'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台', '碧', '峭', '十', '二', '峰', '。'], ['荆', '王'], ['荆', '王', '猎'], ['荆', '王', '猎', '时'], ['荆', '王', '猎', '时', '逢'], ['荆', '王', '猎', '时', '逢', '暮']]\n",
      "13095\n"
     ]
    }
   ],
   "source": [
    "# 在训练集将数据整理成模型便于训练的格式\n",
    "# 由于我们需要预测下一个token，所以我们需要枚举字符串所有的长度大于1的前缀\n",
    "tmp=[sentence[:i] for sentence in corprus for i in range(2,len(sentence)+1)]\n",
    "train_size=int(0.9*len(tmp))\n",
    "train=tmp[:train_size]\n",
    "test=tmp[train_size:]\n",
    "print(len(tmp))\n",
    "print(tmp[:20])\n",
    "print(train_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成式语言模型建模建模\n",
    "\n",
    "使用LSTM和GRU搭建语言模型。使用预测下一个token的方式生成，这种自回归生成方法是目前最主流的生成方法。\n",
    "\n",
    "具体可以参考AK的[字符级语言模型教程](https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2&ab_channel=AndrejKarpathy)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils\n",
    "# 定义模型\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self,d_model,hidden_size,num_layer,output_size,dropout=0.1,bid=False) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.hidden_size=hidden_size\n",
    "        self.layers=num_layer\n",
    "        self.bid=bid\n",
    "        \n",
    "        self.rnn=nn.GRU(d_model,hidden_size,num_layer,\\\n",
    "                        batch_first=True,dropout=dropout,bidirectional=bid)\n",
    "\n",
    "    def forward(self,X):\n",
    "        if(self.bid==True):\n",
    "            h0=torch.zeros(X.size(0),2*self.num_layer,self.hidden_size)\n",
    "        else:\n",
    "            h0=torch.zeros(X.size(0),self.num_layer,self.hidden_size)\n",
    "        X,h_n=self.rnn(X,h0)\n",
    "        return X,h_n\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,d_model,hidden_size,num_layer,output_size=50,dropout=0.1,bid=False) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.hidden_size=hidden_size\n",
    "        self.layer=num_layer\n",
    "        self.bid=bid\n",
    "        self.rnn=nn.LSTM(d_model,hidden_size,num_layer,\\\n",
    "                        batch_first=True,dropout=dropout,bidirectional=bid)\n",
    "\n",
    "    def forward(self,X,l):\n",
    "        if(self.bid==True):\n",
    "            h0=torch.zeros(2*self.layer,X.size(0),self.hidden_size).to(device)\n",
    "            c0=torch.zeros(2*self.layer,X.size(0),self.hidden_size).to(device)\n",
    "        else:\n",
    "            h0=torch.zeros(self.layer,X.size(0),self.hidden_size).to(device)\n",
    "            c0=torch.zeros(self.layer,X.size(0),self.hidden_size).to(device)\n",
    "        X=rnn_utils.pack_padded_sequence(X,l,batch_first=True,enforce_sorted=False)\n",
    "        X,(hn,cn)=self.rnn(X,(h0,c0))\n",
    "        X,_=rnn_utils.pad_packed_sequence(X,batch_first=True)\n",
    "        return X,hn,cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(Dataset):\n",
    "    def __init__(self,data) -> None:\n",
    "        super().__init__()\n",
    "        self.data=data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        sentence=self.data[index]\n",
    "        sentence_tmp=sen2word2vec(self.data[index])\n",
    "        # sentence_extend=\n",
    "        mask=torch.tril(torch.ones((len(sentence),len(sentence))))\n",
    "        l=[i+1 for i in range(len(self.data[index]))] \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=64\n",
    "epoch=25\n",
    "train_dataset=MyDataSet(train)\n",
    "train_loader=DataLoader(train_dataset,batch_size=batchsize,shuffle=True)\n",
    "test_dataset=MyDataSet(test)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batchsize,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poet(nn.Module):\n",
    "    def __init__(self,d_model,hidden_size,model=\"GRU\") -> None:\n",
    "        super().__init__()\n",
    "        if(model==\"GRU\"):\n",
    "            self.model=GRU(d_model=d_model,hidden_size=hidden_size,output_size=d_model)\n",
    "        elif(model==\"LSTM\"):\n",
    "            self.model=LSTM(d_model=d_model,hidden_size=hidden_size,output_size=d_model)\n",
    "\n",
    "\n",
    "    def forward(self,X,l):\n",
    "        pass\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def generate(self,s):\n",
    "        '''\n",
    "        给定句子，然后让模型通过接龙的方式完成接下来的句子。\n",
    "        由于数据中的每个诗句都是以“。”结束的。所以当模型输出“。”时，我们认为模型输出结束\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(mnodel,dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(model,test,config):\n",
    "    '''\n",
    "    测试模型，计算困惑度\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"山水有情亦无情\"\n",
    "poe=Poet(model=\"LSTM\")\n",
    "TrainModel(poe)\n",
    "TestModel(poe)\n",
    "print(poe.generate(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
