{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据分析/处理\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 搭建神经网络\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "# 数据可视化\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# word2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1912d2fc5d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证cuda是否可用\n",
    "cuda_available=torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
    "if cuda_available:\n",
    "    print(\"CUDA Device Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Compute Capability:\", torch.cuda.get_device_capability(0))\n",
    "# 宇宙的答案\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读入数据\n",
    "\n",
    "由于是中文诗词，且需要进行字符级建模，所以需要搭建字典并切分句子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "# 首先将整个语料库读入，并对其进行清洗和重新划分。\n",
    "poe=open(\"poetryFromTang.txt\",'r')\n",
    "poem=poe.read()\n",
    "poe.close()\n",
    "# 将诗词按句号划分\n",
    "tmp=poem.replace(poem[0],\"\")\n",
    "tmp=tmp.replace(\" \",\"\")\n",
    "tmp=tmp.replace(\"。\",\"。\\n\")\n",
    "# 检查有无乱码\n",
    "if('a' in tmp):\n",
    "    print(\"yes\")\n",
    "# 诗词中有乱码，推测为拼音，需要在分词时注意\n",
    "# 作为新文件保存\n",
    "newFile=open(\"NewPoetryFromTang.txt\",'w')\n",
    "newFile.write(tmp)\n",
    "newFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['君', '问', '归', '期', '未', '有', '期', '，', '巴', '山', '夜', '雨', '空', '秋', '池', '。']\n"
     ]
    }
   ],
   "source": [
    "corprus=pd.read_csv(\"NewPoetryFromTang.txt\",header=None,delimiter='\\t')\n",
    "max_len=corprus[0].str.len().max()\n",
    "# print(max_len)\n",
    "def sen2list(sentence):\n",
    "    pattern=r'[a-zA-Z0-9]+'\n",
    "    match=re.findall(pattern,sentence)\n",
    "    # 把句子中的拼音全换成中文字符“空”\n",
    "    for m in match:\n",
    "        sentence=sentence.replace(m,\"空\")\n",
    "    l=[w for w in sentence]\n",
    "    return l\n",
    "s=sen2list(\"君问归期未有期，巴山夜雨zhangqiu1秋池。\")\n",
    "print(s)\n",
    "\n",
    "corprus=corprus[0].apply(sen2list).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用word2vec得到对应的word2vec\n",
    "# 将向量维度设置为50，同时由于是字符级别的模型，所以对所有的字符都要训练，min_count需要设置为1\n",
    "wvmodel=Word2Vec(corprus,vector_size=50,sg=1,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02048546, -0.0339867 , -0.04498263,  0.08610422, -0.01337775,\n",
       "       -0.135335  ,  0.06926418,  0.14860646, -0.10922369, -0.01541629,\n",
       "       -0.03319496, -0.04351404, -0.02356056,  0.12674654, -0.12218582,\n",
       "        0.02924751, -0.01257277,  0.06778406, -0.22253206, -0.08654393,\n",
       "        0.05188347,  0.07344026,  0.18008152, -0.10404909,  0.10820116,\n",
       "       -0.02040414, -0.00903478, -0.06250524, -0.16235857,  0.02753992,\n",
       "        0.07351539, -0.04710708, -0.00964546,  0.06018091, -0.145111  ,\n",
       "        0.08272424,  0.11769059, -0.05723559,  0.04614902, -0.08042441,\n",
       "        0.14436597, -0.01798737, -0.03533059,  0.06652638,  0.23452787,\n",
       "       -0.02284367, -0.00210069, -0.05734519,  0.09644758,  0.10062894],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例子\n",
    "wvmodel.wv[\"巴\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n"
     ]
    }
   ],
   "source": [
    "def sen2word2vec(sentence_list,model,maxlen=max_len):\n",
    "    vecList=np.zeros((maxlen,model.vector_size)) \n",
    "    # vecList=np.zeros((len(sentence_list),model.vector_size)) \n",
    "    \n",
    "    if(sentence_list==[]):\n",
    "        return vecList \n",
    "    # 将列表句子转化为稠密词向量句子\n",
    "    # vecList=np.array([])\n",
    "    for i,e in enumerate(sentence_list):\n",
    "        if(e in model.wv):\n",
    "            vecList[i]=model.wv[e]\n",
    "    return vecList\n",
    "\n",
    "s=['巴','山','夜']\n",
    "p=sen2word2vec(s,wvmodel)\n",
    "print(len(p))\n",
    "print(p[0]==wvmodel.wv['巴'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14550\n",
      "[['巴', '山'], ['巴', '山', '上'], ['巴', '山', '上', '峡'], ['巴', '山', '上', '峡', '重'], ['巴', '山', '上', '峡', '重', '复'], ['巴', '山', '上', '峡', '重', '复', '重'], ['巴', '山', '上', '峡', '重', '复', '重', '，'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台', '碧'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台', '碧', '峭'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台', '碧', '峭', '十'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台', '碧', '峭', '十', '二'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台', '碧', '峭', '十', '二', '峰'], ['巴', '山', '上', '峡', '重', '复', '重', '，', '阳', '台', '碧', '峭', '十', '二', '峰', '。'], ['荆', '王'], ['荆', '王', '猎'], ['荆', '王', '猎', '时'], ['荆', '王', '猎', '时', '逢'], ['荆', '王', '猎', '时', '逢', '暮']]\n",
      "13095\n"
     ]
    }
   ],
   "source": [
    "# 在训练集将数据整理成模型便于训练的格式\n",
    "# 由于我们需要预测下一个token，所以我们需要枚举字符串所有的长度大于1的前缀\n",
    "tmp=[sentence[:i] for sentence in corprus for i in range(2,len(sentence)+1)]\n",
    "train_size=int(0.9*len(tmp))\n",
    "train=tmp[:train_size]\n",
    "test=tmp[train_size:]\n",
    "print(len(tmp))\n",
    "print(tmp[:20])\n",
    "print(train_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成式语言模型建模建模\n",
    "\n",
    "使用LSTM和GRU搭建语言模型。使用预测下一个token的方式生成，这种自回归生成方法是目前最主流的生成方法。\n",
    "\n",
    "具体可以参考AK的[字符级语言模型教程](https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2&ab_channel=AndrejKarpathy)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils\n",
    "# 定义模型\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self,d_model,hidden_size,num_layer,output_size,dropout=0.1,bid=False) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.hidden_size=hidden_size\n",
    "        self.layers=num_layer\n",
    "        self.bid=bid\n",
    "        \n",
    "        self.rnn=nn.GRU(d_model,hidden_size,num_layer,\\\n",
    "                        batch_first=True,dropout=dropout,bidirectional=bid)\n",
    "\n",
    "    def forward(self,X):\n",
    "        if(self.bid==True):\n",
    "            h0=torch.zeros(X.size(0),2*self.num_layer,self.hidden_size)\n",
    "        else:\n",
    "            h0=torch.zeros(X.size(0),self.num_layer,self.hidden_size)\n",
    "        X,h_n=self.rnn(X,h0)\n",
    "        return X,h_n\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,d_model,hidden_size,num_layer,output_size=50,dropout=0.1,bid=False) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.hidden_size=hidden_size\n",
    "        self.layer=num_layer\n",
    "        self.bid=bid\n",
    "        self.rnn=nn.LSTM(d_model,hidden_size,num_layer,\\\n",
    "                        batch_first=True,dropout=dropout,bidirectional=bid)\n",
    "        self.tokengenerate=nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size,out_features=hidden_size,bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size,out_features=hidden_size,bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size,out_features=output_size,bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self,X,l):\n",
    "        if(self.bid==True):\n",
    "            h0=torch.zeros(2*self.layer,X.size(0),self.hidden_size).to(device)\n",
    "            c0=torch.zeros(2*self.layer,X.size(0),self.hidden_size).to(device)\n",
    "        else:\n",
    "            h0=torch.zeros(self.layer,X.size(0),self.hidden_size).to(device)\n",
    "            c0=torch.zeros(self.layer,X.size(0),self.hidden_size).to(device)\n",
    "        X=rnn_utils.pack_padded_sequence(X,l,batch_first=True,enforce_sorted=False)\n",
    "        X,(hn,cn)=self.rnn(X,(h0,c0))\n",
    "        X,_=rnn_utils.pad_packed_sequence(X,batch_first=True)\n",
    "        token_vec=self.tokengenerate(X[:,-1,:])\n",
    "        return token_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(Dataset):\n",
    "    def __init__(self,data) -> None:\n",
    "        super().__init__()\n",
    "        self.data=data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        return sen2word2vec(self.data[index]),len(self.data[index])-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=64\n",
    "epoch=25\n",
    "train_dataset=MyDataSet(train)\n",
    "train_loader=DataLoader(train_dataset,batch_size=batchsize,shuffle=True)\n",
    "test_dataset=MyDataSet(test)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batchsize,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poet(nn.Module):\n",
    "    def __init__(self,d_model,hidden_size,model=\"GRU\") -> None:\n",
    "        super().__init__()\n",
    "        if(model==\"GRU\"):\n",
    "            self.model=GRU(d_model=d_model,hidden_size=hidden_size,output_size=d_model)\n",
    "        elif(model==\"LSTM\"):\n",
    "            self.model=LSTM(d_model=d_model,hidden_size=hidden_size,output_size=d_model)\n",
    "\n",
    "    def forward(self,X,l):\n",
    "        token=self.model(X,l)\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def generate(self,s):\n",
    "        '''\n",
    "        给定句子，然后让模型通过接龙的方式完成接下来的句子。\n",
    "        由于数据中的每个诗句都是以“。”结束的。所以当模型输出“。”时，我们认为模型输出结束\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(mnodel,dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(model,test,config):\n",
    "    '''\n",
    "    测试模型，计算困惑度\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'd_model' and 'hidden_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m s\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m山水有情亦无情\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m poe\u001b[38;5;241m=\u001b[39m\u001b[43mPoet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLSTM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m TrainModel(poe)\n\u001b[0;32m      4\u001b[0m TestModel(poe)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'd_model' and 'hidden_size'"
     ]
    }
   ],
   "source": [
    "s=\"山水有情亦无情\"\n",
    "poe=Poet(d_model=50,hidden_size=100,model=\"LSTM\")\n",
    "TrainModel(poe)\n",
    "TestModel(poe)\n",
    "print(poe.generate(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
